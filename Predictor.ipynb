{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pywt\n",
    "from scipy import signal\n",
    "import math\n",
    "from math import *\n",
    "from numpy import *\n",
    "import sys\n",
    "from biosppy.signals import ecg\n",
    "import statistics\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pywt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "#model = load_model('Models/best_model.08-0.17.h5')\n",
    "model = load_model('Models/best_model.01-0.04.h5') #Insert model here\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target dataset\n",
    "data = pd.read_csv(\"PTB_processed_new/record333_patient121_Healthy control.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Loaded\n"
     ]
    }
   ],
   "source": [
    "# Process data to be similar to input training data\n",
    "signal_array = []\n",
    "file_array = []\n",
    "for column in data:\n",
    "    if column != 'vx' and column != 'vy' and column != 'vz':\n",
    "        df = data[column]\n",
    "        arrays = np.array(df)\n",
    "        arrays = baseline_corr(arrays)\n",
    "        peak = signal.argrelmax(arrays, order = 450)\n",
    "        start = peak[0][2] - 200\n",
    "        end = peak[0][2] + 400\n",
    "        arrays = arrays[start:end]\n",
    "        arrays = wavelet_denoise(arrays)\n",
    "        arrays = signal.resample(arrays, 150)\n",
    "        file_array.append(arrays)\n",
    "\n",
    "signal_array.append(file_array)\n",
    "signal_array = np.asarray(signal_array).reshape(-1, 150, 12)\n",
    "\n",
    "print ('Input Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Loaded\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# Process data to be similar to input training data\n",
    "signal_array = []\n",
    "file_array = []\n",
    "\n",
    "#data = baseline.baseline_corr(data)\n",
    "#data = wden.wdenoise(data, 'sqtwolog', 'soft', 'mln', 4, 'sym7')\n",
    "df = np.array(data['v4'])\n",
    "    \n",
    "peaks = ecg.christov_segmenter(df, 250)[0]\n",
    "for peak in range (1, len(peaks) - 1):\n",
    "    segment_array = []\n",
    "    for column in data:\n",
    "        df = np.array(data[column])\n",
    "        segment = df[peaks[peak]-50:peaks[peak]+100]\n",
    "        segment_array.append(segment)  \n",
    "    signal_array.append(segment_array)\n",
    "\n",
    "signal_array = np.asarray(signal_array).reshape(-1, 150, 12)\n",
    "\n",
    "print ('Input Loaded')\n",
    "print (signal_array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data into 12 sections (Only use if the rest breaks)\n",
    "input1 = signal_array[:, :, 0].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input2 = signal_array[:, :, 1].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input3 = signal_array[:, :, 2].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input4 = signal_array[:, :, 3].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input5 = signal_array[:, :, 4].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input6 = signal_array[:, :, 5].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input7 = signal_array[:, :, 6].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input8 = signal_array[:, :, 7].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input9 = signal_array[:, :, 8].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input10 = signal_array[:, :, 9].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input11 = signal_array[:, :, 10].reshape(signal_array.shape[0], signal_array.shape[1], 1)\n",
    "input12 = signal_array[:, :, 11].reshape(signal_array.shape[0], signal_array.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor (Only use if the rest breaks)\n",
    "y_pred_test = model.predict([input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11, input12], verbose = 1)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "prediction = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "labels = ['Bundle branch block', 'Cardiomyopathy', 'Dysrhythmia', 'Healthy control', 'Hypertrophy', 'Myocardial infarction', 'Myocarditis', 'Stable angina', 'Valvular heart disease']\n",
    "\n",
    "print (labels[int(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tansh\\AppData\\Local\\Temp\\ipykernel_2512\\3731628915.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(labels[int(prediction)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Bundle branch block\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range (signal_array.shape[0]):\n",
    "    input1 = signal_array[i, :, 0].reshape(1, signal_array.shape[1], 1)\n",
    "    input2 = signal_array[i, :, 1].reshape(1, signal_array.shape[1], 1)\n",
    "    input3 = signal_array[i, :, 2].reshape(1, signal_array.shape[1], 1)\n",
    "    input4 = signal_array[i, :, 3].reshape(1, signal_array.shape[1], 1)\n",
    "    input5 = signal_array[i, :, 4].reshape(1, signal_array.shape[1], 1)\n",
    "    input6 = signal_array[i, :, 5].reshape(1, signal_array.shape[1], 1)\n",
    "    input7 = signal_array[i, :, 6].reshape(1, signal_array.shape[1], 1)\n",
    "    input8 = signal_array[i, :, 7].reshape(1, signal_array.shape[1], 1)\n",
    "    input9 = signal_array[i, :, 8].reshape(1, signal_array.shape[1], 1)\n",
    "    input10 = signal_array[i, :, 9].reshape(1, signal_array.shape[1], 1)\n",
    "    input11 = signal_array[i, :, 10].reshape(1, signal_array.shape[1], 1)\n",
    "    input12 = signal_array[i, :, 11].reshape(1, signal_array.shape[1], 1)\n",
    "    \n",
    "    # Predictor\n",
    "    y_pred_test = model.predict([input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11, input12], verbose = 1)\n",
    "    # Take the class with the highest probability from the test predictions\n",
    "    prediction = np.argmax(y_pred_test, axis=1)\n",
    "    \n",
    "    labels = ['Bundle branch block', 'Cardiomyopathy', 'Dysrhythmia', 'Healthy control', 'Hypertrophy', 'Myocardial infarction', 'Myocarditis' 'Stable angina'\n",
    " 'Valvular heart disease']\n",
    "    predictions.append(labels[int(prediction)])\n",
    "    #print (labels[int(prediction)])\n",
    "    \n",
    "\n",
    "final_prediction = statistics.mode(predictions) \n",
    "print (final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 150, 12)\n"
     ]
    }
   ],
   "source": [
    "print (signal_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoise(data, wavelet='sym7', level=4, mode='soft'): #Update\n",
    "    coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "    threshold = np.sqrt(2 * np.log(len(data))) * np.median(np.abs(coeffs[-level])) / 0.6745\n",
    "    coeffs[1:] = [pywt.threshold(c, threshold, mode=mode) for c in coeffs[1:]]\n",
    "    return pywt.waverec(coeffs, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_corr(array):\n",
    "    # Function for use in baseline removal\n",
    "    def wrcoef(X, coef_type, coef, wavename, level):\n",
    "        N = np.array(X).size\n",
    "        a, ds = coef[0], list(reversed(coef[1:]))\n",
    "\n",
    "        if coef_type =='a':\n",
    "            return pywt.upcoef('a', a, wavename, level=level)[:N]\n",
    "        elif coef_type == 'd':\n",
    "            return pywt.upcoef('d', ds[level-1], wavename, level=level)[:N]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid coefficient type: {}\".format(coef_type))\n",
    "    #Baseline correction variables\n",
    "    wavename = 'db1'\n",
    "    #Baseline correction\n",
    "    coef = pywt.wavedec(array, wavename, level=10)\n",
    "    A10 = wrcoef(array, 'a', coef, wavename, 10)\n",
    "    D10 = wrcoef(array, 'd', coef, wavename, 10)\n",
    "    D9 = wrcoef(array, 'd', coef, wavename, 9)\n",
    "    D8 = wrcoef(array, 'd', coef, wavename, 8)\n",
    "    D7 = wrcoef(array, 'd', coef, wavename, 7)\n",
    "    D6 = wrcoef(array, 'd', coef, wavename, 6)\n",
    "    D5 = wrcoef(array, 'd', coef, wavename, 5)\n",
    "    D4 = wrcoef(array, 'd', coef, wavename, 4)\n",
    "    D3 = wrcoef(array, 'd', coef, wavename, 3)\n",
    "    D2 = wrcoef(array, 'd', coef, wavename, 2)\n",
    "    D1 = wrcoef(array, 'd', coef, wavename, 1)\n",
    "    array = D10 + D9 + D8 + D7 + D6 + D5 + D4 + D3 + D2 + D1\n",
    "    return array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
