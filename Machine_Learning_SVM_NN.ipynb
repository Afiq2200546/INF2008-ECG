{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nj6QIlF3Zl3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from biosppy.signals import ecg\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj6lCEs23ZmI"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Set filepath\n",
        "filepath = 'PTB_processed_new'\n",
        "total = len(os.listdir(filepath))\n",
        "\n",
        "# Load label file\n",
        "labels_file = pd.read_csv(\"new_labels.csv\", header=0)\n",
        "labels = np.asarray(labels_file['diagnosis'])\n",
        "\n",
        "# Create empty containers\n",
        "signal_array = []  # To store all segments\n",
        "label_array = []   # To store all labels\n",
        "\n",
        "# Create counters\n",
        "files_completed = 0\n",
        "file_number = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IJXOH7X3ZmS"
      },
      "outputs": [],
      "source": [
        "# Signal Extractor\n",
        "start_time = time.time()\n",
        "for filename in os.listdir(filepath):\n",
        "    start_time_file = time.time()\n",
        "    data = pd.read_csv(os.path.join(filepath, filename), header=0, engine='python')\n",
        "    file_label = labels[file_number]\n",
        "    df = np.array(data['v4'])\n",
        "    peaks = ecg.christov_segmenter(df, 1000)[0]\n",
        "\n",
        "    for peak in range(1, len(peaks) - 1):\n",
        "        segment_array = []  # To store one segment\n",
        "        for column in data:\n",
        "            col_data = np.array(data[column])\n",
        "            segment = col_data[peaks[peak] - 50:peaks[peak] + 100]\n",
        "            segment_array.append(segment)\n",
        "        signal_array.append(segment_array)\n",
        "        label_array.append(file_label)\n",
        "\n",
        "    files_completed += 1\n",
        "    file_number += 1\n",
        "    progress = round(files_completed / total * 100, 2)  # Updated variable here\n",
        "    end_time_file = time.time()\n",
        "    elapsed_time_file = round(end_time_file - start_time_file, 2)\n",
        "    sys.stdout.write(f'\\r{filename} loaded - {progress}% completed - Took: {elapsed_time_file} seconds')\n",
        "\n",
        "\n",
        "signal_array = np.asarray(signal_array)\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 2)\n",
        "print(f'\\nData loading completed: {files_completed} files - Took: {elapsed_time} seconds')\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "data_labels = le.fit_transform(label_array)\n",
        "num_classes = le.classes_.size\n",
        "print(le.classes_)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "print(f'{len(label_array)} Labels loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SftZZIrQ3ZmV"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(signal_array, data_labels, test_size=0.3, random_state=7)\n",
        "\n",
        "# Flatten the data to convert each sample to a single feature vector\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Impute missing values using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "Y_test_tensor = torch.tensor(Y_test, dtype=torch.long).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLR-X43l3ZmX"
      },
      "outputs": [],
      "source": [
        "# Neural Network\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        # Feature extractor\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # Final classifier layer\n",
        "        self.classifier = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        out = self.classifier(features)\n",
        "        return out\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        with torch.no_grad():\n",
        "            return self.feature_extractor(x)\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = MLP(input_dim, num_classes).to(device)\n",
        "\n",
        "# Training settings\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 50\n",
        "\n",
        "# Training loop for the PyTorch MLP\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, Y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Switch to evaluation mode and extract features\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    train_features = model.extract_features(X_train_tensor).cpu().numpy()\n",
        "    test_features = model.extract_features(X_test_tensor).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDA49ydG3ZmZ"
      },
      "outputs": [],
      "source": [
        "# Train an SVM classifier on the extracted features\n",
        "svm = SVC(kernel='linear', probability=True)\n",
        "svm.fit(train_features, Y_train)\n",
        "\n",
        "# Make predictions with the SVM\n",
        "y_pred_test = svm.predict(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAjfoUPi3Zmd"
      },
      "outputs": [],
      "source": [
        "def show_confusion_matrix(true_labels, predicted_labels):\n",
        "    matrix = metrics.confusion_matrix(true_labels, predicted_labels)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(matrix, cmap='coolwarm', linecolor='white', linewidths=1,\n",
        "                xticklabels=le.classes_, yticklabels=le.classes_, annot=True, fmt='d')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_confusion_matrix(Y_test, y_pred_test)\n",
        "print(classification_report(Y_test, y_pred_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}