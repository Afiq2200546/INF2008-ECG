{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies\n",
    "\n",
    "Imports required libraries for file handling (os, shutil, sys, time), data processing (numpy, pandas), and signal processing (pywt, scipy.signal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Patient Labels\n",
    "\n",
    "Reads new_labels.csv and converts patient IDs, header file names, and diagnoses into NumPy arrays for easy processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patient labels\n",
    "label = pd.read_csv(\"new_labels.csv\", header=0, names=('patient', 'header file', 'diagnosis'))\n",
    "patient_array = np.array(label['patient'])\n",
    "original_file_array = np.array(label['header file'])\n",
    "diagnosis_array = np.array(label['diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Correction Function\n",
    "\n",
    "Defines baseline_corr() to remove baseline drift from ECG signals using wavelet decomposition and reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for baseline correction\n",
    "def baseline_corr(array):\n",
    "    # Function for use in baseline removal\n",
    "    def wrcoef(X, coef_type, coef, wavename, level):\n",
    "        N = np.array(X).size\n",
    "        a, ds = coef[0], list(reversed(coef[1:]))\n",
    "\n",
    "        if coef_type == 'a':\n",
    "            return pywt.upcoef('a', a, wavename, level=level)[:N]\n",
    "        elif coef_type == 'd':\n",
    "            return pywt.upcoef('d', ds[level - 1], wavename, level=level)[:N]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid coefficient type: {}\".format(coef_type))\n",
    "\n",
    "    # Baseline correction variables\n",
    "    waveName = 'db1'\n",
    "    # Baseline correction\n",
    "    coefficient = pywt.wavedec(array, waveName, level=10)\n",
    "    # A10 = wrcoef(array, 'a', coefficient, waveName, 10)\n",
    "    D10 = wrcoef(array, 'd', coefficient, waveName, 10)\n",
    "    D9 = wrcoef(array, 'd', coefficient, waveName, 9)\n",
    "    D8 = wrcoef(array, 'd', coefficient, waveName, 8)\n",
    "    D7 = wrcoef(array, 'd', coefficient, waveName, 7)\n",
    "    D6 = wrcoef(array, 'd', coefficient, waveName, 6)\n",
    "    D5 = wrcoef(array, 'd', coefficient, waveName, 5)\n",
    "    D4 = wrcoef(array, 'd', coefficient, waveName, 4)\n",
    "    D3 = wrcoef(array, 'd', coefficient, waveName, 3)\n",
    "    D2 = wrcoef(array, 'd', coefficient, waveName, 2)\n",
    "    D1 = wrcoef(array, 'd', coefficient, waveName, 1)\n",
    "    array = D10 + D9 + D8 + D7 + D6 + D5 + D4 + D3 + D2 + D1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wavelet Denoising Function\n",
    "\n",
    "Defines wavelet_denoise() to apply wavelet thresholding for noise removal in ECG signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for wavelet denoising\n",
    "def wavelet_denoise(dataframe, wavelet='sym7', level=4, mode='soft'):  # Update\n",
    "    coefficients = pywt.wavedec(dataframe, wavelet, level=level)\n",
    "    threshold = np.sqrt(2 * np.log(len(dataframe))) * np.median(np.abs(coefficients[-level])) / 0.6745\n",
    "    coefficients[1:] = [pywt.threshold(c, threshold, mode=mode) for c in coefficients[1:]]\n",
    "    return pywt.waverec(coefficients, wavelet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process ECG Signals\n",
    "\n",
    "Iterates through patient data, applies baseline_corr() and wavelet_denoise(), resamples the signals, and saves processed ECG data in a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient083 loaded - 47.57281553398058% completed Took : 0.14 secondss"
     ]
    }
   ],
   "source": [
    "# Process ECG signals\n",
    "patient = []\n",
    "diagnosis = []\n",
    "original_file = []\n",
    "signal_num = 0\n",
    "skipped = 0\n",
    "filepath = \"ptb-diagnostic-ecg-database-1.0.0\"\n",
    "if os.path.exists('PTB_processed_new'):\n",
    "    shutil.rmtree('PTB_processed_new')\n",
    "os.makedirs('PTB_processed_new')\n",
    "for i in range(len(patient_array)):  # For each line in new_labels\n",
    "    p_string = str(patient_array[i])\n",
    "    f_string = str(original_file_array[i])\n",
    "    full_filepath = filepath + '/' + p_string + '/' + f_string + '.csv'\n",
    "    if os.path.exists(full_filepath):\n",
    "        data = pd.read_csv(\n",
    "            full_filepath,\n",
    "            header=0,\n",
    "            skiprows=1,\n",
    "            usecols=list(range(1, 13)),\n",
    "            engine='python'\n",
    "        )\n",
    "        start_time = time.time()\n",
    "        patient.append(p_string)\n",
    "        original_file.append(f_string)\n",
    "        diagnosis.append(diagnosis_array[i])\n",
    "        signal_num += 1\n",
    "        if signal_num < 10:\n",
    "            mod_signal = '00' + str(signal_num)\n",
    "        elif signal_num < 100:\n",
    "            mod_signal = '0' + str(signal_num)\n",
    "        else:\n",
    "            mod_signal = str(signal_num)\n",
    "        file_array = []\n",
    "        for column in data:  # Processing\n",
    "            df = np.array(data[column])\n",
    "            df = baseline_corr(df)\n",
    "            df = wavelet_denoise(df)  # Updated\n",
    "            df = df[0:30000]\n",
    "            df = signal.resample(df, 7500)\n",
    "            file_array.append(df)\n",
    "        newdata = pd.concat([pd.Series(file_array[0]),\n",
    "                             pd.Series(file_array[1]),\n",
    "                             pd.Series(file_array[2]),\n",
    "                             pd.Series(file_array[3]),\n",
    "                             pd.Series(file_array[4]),\n",
    "                             pd.Series(file_array[5]),\n",
    "                             pd.Series(file_array[6]),\n",
    "                             pd.Series(file_array[7]),\n",
    "                             pd.Series(file_array[8]),\n",
    "                             pd.Series(file_array[9]),\n",
    "                             pd.Series(file_array[10]),\n",
    "                             pd.Series(file_array[11]), ], axis=1)\n",
    "        newdata.columns = ['i', 'ii', 'iii', 'avr', 'avl', 'avf', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "        newdata.to_csv(\n",
    "            'PTB_processed_new/record' + mod_signal + '_' + p_string + '_' + str(diagnosis_array[i]) + '.csv',\n",
    "            index=False)\n",
    "        completion = (i / len(patient_array)) * 100\n",
    "        end_time = time.time()\n",
    "        elapsed_time = round(end_time - start_time, 2)\n",
    "        sys.stdout.write('\\r' + p_string + ' loaded - ' + str(completion) + '% completed' + ' Took : ' + str(\n",
    "            elapsed_time) + ' seconds')\n",
    "    else:\n",
    "        print(\"Skipped \" + p_string + \" file \" + f_string)\n",
    "        skipped += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Processed Labels\n",
    "\n",
    "Saves the processed patient labels to new_labels_processed.csv and prints the number of processed and skipped signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done: 546 signals processed and loaded 3 skipped\n"
     ]
    }
   ],
   "source": [
    "# Save processed labels\n",
    "label_df = pd.concat([pd.Series(patient), pd.Series(original_file), pd.Series(diagnosis)], axis=1)\n",
    "label_df.columns = ['patient', 'original_file', 'diagnosis']\n",
    "label_df.to_csv('new_labels_processed.csv')\n",
    "\n",
    "print('')\n",
    "print('Done: ' + str(signal_num) + ' signals processed and loaded ' + str(skipped) + \" skipped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
